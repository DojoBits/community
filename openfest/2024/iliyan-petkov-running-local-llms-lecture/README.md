<div align="center">
  <h1 style="font-size: 30px;" align="center">OpenFest 2024</h1>
  <br/>
  <h2 align="center">Iliyan Petkov - Lecture</h2>
  <h3 align="center">Running Local LLMs</h3>

  <picture>
    <img src="./img/ip-openfest2024.jpg" alt="Iliyan Petkov - OpenFest 2024" width=70%>
  </picture>
</div>

## Overview

Cloud-based LLMs like ChatGPT, Claude, and Gemini offer powerful capabilities but
raise concerns about data privacy and vendor lock-in. Local open-source LLMs offer
an alternative, allowing users to take back control over their data, customize
the models, and reduce costs. This talk will explore the benefits and challenges
of running local LLMs. We will also discuss choosing the right LLM for your needs,
the tools for managing local models, and effective prompt engineering techniques
for interacting with them. By understanding the advantages and challenges of local
LLMs, you can harness the power of AI while protecting your privacy and maintaining
control over your data.